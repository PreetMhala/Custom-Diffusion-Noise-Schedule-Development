{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13602561,"sourceType":"datasetVersion","datasetId":8643764},{"sourceId":14131570,"sourceType":"datasetVersion","datasetId":9004558},{"sourceId":681625,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":517242,"modelId":531896}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ============================================================\n# ğŸ“¦ SETUP\n# ============================================================\n!git clone https://github.com/NVlabs/edm2.git /kaggle/working/edm2\n%cd /kaggle/working/edm2\n!pip install click tqdm psutil scipy pillow matplotlib --quiet\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-12T18:36:21.948504Z","iopub.execute_input":"2025-12-12T18:36:21.949228Z","iopub.status.idle":"2025-12-12T18:36:28.921652Z","shell.execute_reply.started":"2025-12-12T18:36:21.949180Z","shell.execute_reply":"2025-12-12T18:36:28.920798Z"}},"outputs":[{"name":"stdout","text":"Cloning into '/kaggle/working/edm2'...\nremote: Enumerating objects: 60, done.\u001b[K\nremote: Counting objects: 100% (27/27), done.\u001b[K\nremote: Compressing objects: 100% (17/17), done.\u001b[K\nremote: Total 60 (delta 13), reused 10 (delta 10), pack-reused 33 (from 1)\u001b[K\nReceiving objects: 100% (60/60), 1.27 MiB | 9.58 MiB/s, done.\nResolving deltas: 100% (24/24), done.\n/kaggle/working/edm2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# ============================================================\n# ğŸ“¦ SETUP\n# ============================================================\n\n!pip install pillow pandas numpy torch --quiet\n\nimport os, math, pickle, torch\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image, ImageDraw, ImageFont\nfrom pathlib import Path\n\nimport sys\nsys.path.append(\"/kaggle/working/edm2\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T18:37:09.088862Z","iopub.execute_input":"2025-12-12T18:37:09.089522Z","iopub.status.idle":"2025-12-12T18:38:33.382121Z","shell.execute_reply.started":"2025-12-12T18:37:09.089488Z","shell.execute_reply":"2025-12-12T18:38:33.381510Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ============================================================\n# ğŸ§© LOAD LANDMARK TEST DATA\n# ============================================================\n\nLANDMARK_CSV = \"/kaggle/input/landmark-for/celeba64_landmarks_transformed.csv\"\nTEST_DIR     = \"/kaggle/input/celeva-64x64-dataset/celeba64/test\"\n\ndf = pd.read_csv(LANDMARK_CSV)\n\nimg_col = \"image_id\"\nlm_cols = df.columns[1:]   # 10 landmark coords\n\n# Keep only test images\ntest_files = sorted(os.listdir(TEST_DIR))\ndf_test = df[df[img_col].isin(test_files)].reset_index(drop=True)\n\nlandmarks = df_test[lm_cols].values.astype(np.float32)\nfilenames = df_test[img_col].values\n\nprint(\"Test samples:\", len(df_test))\nprint(\"Landmark shape:\", landmarks.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T18:38:33.383402Z","iopub.execute_input":"2025-12-12T18:38:33.383725Z","iopub.status.idle":"2025-12-12T18:38:34.782462Z","shell.execute_reply.started":"2025-12-12T18:38:33.383702Z","shell.execute_reply":"2025-12-12T18:38:34.781562Z"}},"outputs":[{"name":"stdout","text":"Test samples: 19962\nLandmark shape: (19962, 10)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# ============================================================\n# ğŸ§  SELECT 3 LANDMARK EXPERIMENTS\n# ============================================================\n\n# Landmark indices\nLE_X, LE_Y = 0, 1\nRE_X, RE_Y = 2, 3\n\n# Inter-eye distance\neye_dist = np.sqrt(\n    (landmarks[:, LE_X] - landmarks[:, RE_X])**2 +\n    (landmarks[:, LE_Y] - landmarks[:, RE_Y])**2\n)\n\n# Horizontal eye alignment (|y_left - y_right|)\neye_y_diff = np.abs(landmarks[:, LE_Y] - landmarks[:, RE_Y])\n\nidx_max_face = np.argmax(eye_dist)\nidx_min_face = np.argmin(eye_dist)\nidx_symmetric = np.argmin(eye_y_diff)\n\nEXPERIMENTS = {\n    \"max_face\": idx_max_face,\n    \"min_face\": idx_min_face,\n    \"symmetric_face\": idx_symmetric,\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T18:38:34.783387Z","iopub.execute_input":"2025-12-12T18:38:34.783700Z","iopub.status.idle":"2025-12-12T18:38:35.917224Z","shell.execute_reply.started":"2025-12-12T18:38:34.783672Z","shell.execute_reply":"2025-12-12T18:38:35.916642Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# ============================================================\n# ğŸ§¾ PRINT LANDMARKS FOR EACH EXPERIMENT\n# ============================================================\n\nfor name, idx in EXPERIMENTS.items():\n    print(\"\\n\" + \"=\"*60)\n    print(name.upper())\n    print(\"=\"*60)\n    print(\"Image:\", filenames[idx])\n    for c, v in zip(lm_cols, landmarks[idx]):\n        print(f\"{c:15s}: {v:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T18:38:35.917963Z","iopub.execute_input":"2025-12-12T18:38:35.918211Z","iopub.status.idle":"2025-12-12T18:38:35.923876Z","shell.execute_reply.started":"2025-12-12T18:38:35.918191Z","shell.execute_reply":"2025-12-12T18:38:35.923040Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nMAX_FACE\n============================================================\nImage: 198369.jpg\nlefteye_x      : 23.37\nlefteye_y      : 35.96\nrighteye_x     : 42.07\nrighteye_y     : 31.64\nnose_x         : 35.96\nnose_y         : 44.22\nleftmouth_x    : 23.73\nleftmouth_y    : 45.66\nrightmouth_x   : 36.31\nrightmouth_y   : 44.94\n\n============================================================\nMIN_FACE\n============================================================\nImage: 193355.jpg\nlefteye_x      : 30.92\nlefteye_y      : 30.20\nrighteye_x     : 32.72\nrighteye_y     : 29.84\nnose_x         : 23.01\nnose_y         : 41.35\nleftmouth_x    : 30.56\nleftmouth_y    : 52.85\nrightmouth_x   : 32.72\nrightmouth_y   : 52.85\n\n============================================================\nSYMMETRIC_FACE\n============================================================\nImage: 182643.jpg\nlefteye_x      : 25.17\nlefteye_y      : 32.72\nrighteye_x     : 38.47\nrighteye_y     : 32.72\nnose_x         : 32.36\nnose_y         : 40.63\nleftmouth_x    : 26.25\nleftmouth_y    : 47.46\nrightmouth_x   : 37.39\nrightmouth_y   : 47.82\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# ============================================================\n# ğŸ“¦ LOAD LANDMARK-CONDITIONAL MODEL\n# ============================================================\n\nMODEL_PKL = \"/kaggle/input/network-snapshot-0001572-0-100-landmark-kr/pytorch/default/1/network-snapshot-0001572-0.100_landmark_kr.pkl\"\n\ndevice = torch.device(\"cuda\")\n\nwith open(MODEL_PKL, \"rb\") as f:\n    net = pickle.load(f)[\"ema\"].to(device).eval()\n\nprint(\"âœ… Landmark-conditional model loaded\")\nprint(\"Condition dim:\", net.label_dim)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T18:38:35.925683Z","iopub.execute_input":"2025-12-12T18:38:35.925901Z","iopub.status.idle":"2025-12-12T18:38:39.861657Z","shell.execute_reply.started":"2025-12-12T18:38:35.925885Z","shell.execute_reply":"2025-12-12T18:38:39.861012Z"}},"outputs":[{"name":"stdout","text":"âœ… Landmark-conditional model loaded\nCondition dim: 10\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# ============================================================\n# ğŸ§ª EDM SAMPLER WITH STEP SAVING (KARRAS)\n# ============================================================\n\ndef edm_sampler_with_steps(\n    net, noise, labels, save_dir,\n    num_steps=32, sigma_min=0.002, sigma_max=80, rho=7\n):\n    os.makedirs(save_dir, exist_ok=True)\n    device = noise.device\n\n    i = torch.arange(num_steps, device=device)\n    sigmas = (\n        sigma_max ** (1 / rho)\n        + i / (num_steps - 1)\n        * (sigma_min ** (1 / rho) - sigma_max ** (1 / rho))\n    ) ** rho\n\n    sigmas = torch.cat([sigmas, torch.zeros_like(sigmas[:1])])\n\n    def denoise(x, t):\n        return net(x, t, labels)\n\n    x = noise * sigmas[0]\n\n    for i in range(num_steps):\n        d = (x - denoise(x, sigmas[i])) / sigmas[i]\n        x = x + (sigmas[i+1] - sigmas[i]) * d\n\n        img = x[0].detach().cpu().clamp(-1,1)\n        img = ((img+1)/2*255).permute(1,2,0).numpy().astype(np.uint8)\n        Image.fromarray(img).save(f\"{save_dir}/step_{i:03d}.png\")\n\n    return sigmas\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T18:38:39.862283Z","iopub.execute_input":"2025-12-12T18:38:39.862505Z","iopub.status.idle":"2025-12-12T18:38:39.869112Z","shell.execute_reply.started":"2025-12-12T18:38:39.862487Z","shell.execute_reply":"2025-12-12T18:38:39.868323Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# ============================================================\n# ğŸš€ RUN 3 LANDMARK CONDITIONAL TRAJECTORIES\n# ============================================================\n\nC, H, W = net.img_channels, net.img_resolution, net.img_resolution\n\nfor name, idx in EXPERIMENTS.items():\n    print(f\"\\nğŸš€ Running {name}\")\n\n    noise = torch.randn(1, C, H, W, device=device)\n    label = torch.tensor(landmarks[idx], device=device).unsqueeze(0)\n\n    outdir = f\"/kaggle/working/landmark_{name}_steps\"\n\n    sigmas = edm_sampler_with_steps(\n        net=net,\n        noise=noise,\n        labels=label,\n        save_dir=outdir,\n        num_steps=32,\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T18:38:39.869976Z","iopub.execute_input":"2025-12-12T18:38:39.870219Z","iopub.status.idle":"2025-12-12T18:38:47.235854Z","shell.execute_reply.started":"2025-12-12T18:38:39.870193Z","shell.execute_reply":"2025-12-12T18:38:47.235297Z"}},"outputs":[{"name":"stdout","text":"\nğŸš€ Running max_face\n\nğŸš€ Running min_face\n\nğŸš€ Running symmetric_face\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# ============================================================\n# ğŸ–¼ï¸ SAVE 4Ã—8 GRID WITH Ïƒ LABELS\n# ============================================================\n\ndef save_grid(step_dir, sigmas, out_path):\n    imgs = [Image.open(f\"{step_dir}/step_{i:03d}.png\") for i in range(32)]\n    w, h = imgs[0].size\n\n    COLS, ROWS = 8, 4\n    TOP = 32\n    GAP = 18\n\n    canvas = Image.new(\"RGB\", (COLS*w, ROWS*(h+TOP+GAP)), \"white\")\n    draw = ImageDraw.Draw(canvas)\n\n    try:\n        font = ImageFont.truetype(\"DejaVuSans.ttf\", 13)\n    except:\n        font = ImageFont.load_default()\n\n    for i, img in enumerate(imgs):\n        r, c = divmod(i, COLS)\n        x = c*w\n        y = r*(h+TOP+GAP)\n\n        draw.text((x+w//2, y+10), f\"Ïƒ={sigmas[i]:.2f}\", anchor=\"mm\", font=font)\n        canvas.paste(img, (x, y+TOP))\n\n    canvas.save(out_path)\n    print(\"âœ… Saved:\", out_path)\n\nfor name in EXPERIMENTS:\n    save_grid(\n        f\"/kaggle/working/landmark_{name}_steps\",\n        sigmas,\n        f\"/kaggle/working/landmark_{name}_grid.png\"\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T18:38:47.236623Z","iopub.execute_input":"2025-12-12T18:38:47.236859Z","iopub.status.idle":"2025-12-12T18:38:47.409023Z","shell.execute_reply.started":"2025-12-12T18:38:47.236833Z","shell.execute_reply":"2025-12-12T18:38:47.408395Z"}},"outputs":[{"name":"stdout","text":"âœ… Saved: /kaggle/working/landmark_max_face_grid.png\nâœ… Saved: /kaggle/working/landmark_min_face_grid.png\nâœ… Saved: /kaggle/working/landmark_symmetric_face_grid.png\n","output_type":"stream"}],"execution_count":9}]}