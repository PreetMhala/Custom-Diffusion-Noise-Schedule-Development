{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b85ec34",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-14T02:56:31.301327Z",
     "iopub.status.busy": "2025-11-14T02:56:31.301121Z",
     "iopub.status.idle": "2025-11-14T02:56:37.977071Z",
     "shell.execute_reply": "2025-11-14T02:56:37.976222Z"
    },
    "papermill": {
     "duration": 6.679722,
     "end_time": "2025-11-14T02:56:37.978402",
     "exception": false,
     "start_time": "2025-11-14T02:56:31.298680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '/kaggle/working/edm2'...\r\n",
      "remote: Enumerating objects: 60, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (27/27), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (17/17), done.\u001b[K\r\n",
      "remote: Total 60 (delta 13), reused 10 (delta 10), pack-reused 33 (from 1)\u001b[K\r\n",
      "Receiving objects: 100% (60/60), 1.27 MiB | 9.80 MiB/s, done.\r\n",
      "Resolving deltas: 100% (24/24), done.\r\n",
      "/kaggle/working/edm2\n",
      "/kaggle/working/edm2\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ✅ SETUP\n",
    "# ============================================================\n",
    "\n",
    "!git clone https://github.com/NVlabs/edm2.git /kaggle/working/edm2\n",
    "%cd /kaggle/working/edm2\n",
    "!pip install click tqdm psutil scipy pillow --quiet\n",
    "%cd /kaggle/working/edm2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3df62d9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T02:56:37.983473Z",
     "iopub.status.busy": "2025-11-14T02:56:37.982954Z",
     "iopub.status.idle": "2025-11-14T02:56:44.335898Z",
     "shell.execute_reply": "2025-11-14T02:56:44.335092Z"
    },
    "papermill": {
     "duration": 6.356758,
     "end_time": "2025-11-14T02:56:44.337098",
     "exception": false,
     "start_time": "2025-11-14T02:56:37.980340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Linear training schedule injected successfully!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ✅ PATCH: LINEAR TRAINING NOISE SCHEDULE\n",
    "# ============================================================\n",
    "import torch\n",
    "import training.training_loop as loop\n",
    "\n",
    "def linear_sigma(batch_size, device, sigma_min=0.002, sigma_max=80):\n",
    "    \"\"\"\n",
    "    Sample sigma linearly between sigma_max → sigma_min.\n",
    "    t ~ U[0,1]\n",
    "    sigma(t) = sigma_max - (sigma_max - sigma_min) * t\n",
    "    \"\"\"\n",
    "    t = torch.rand(batch_size, 1, 1, 1, device=device)\n",
    "    return sigma_max - (sigma_max - sigma_min) * t\n",
    "\n",
    "\n",
    "def patched_call(self, net, images, labels=None):\n",
    "    \"\"\"\n",
    "    This replaces EDM2Loss.__call__ entirely.\n",
    "    Training noise schedule is now linear, not log-normal.\n",
    "    \"\"\"\n",
    "    batch = images.shape[0]\n",
    "\n",
    "    # === LINEAR NOISE SCHEDULE ===\n",
    "    sigma = linear_sigma(batch, images.device)\n",
    "\n",
    "    # === EDM2 original weighting formula ===\n",
    "    weight = (sigma**2 + self.sigma_data**2) / (sigma * self.sigma_data)**2\n",
    "\n",
    "    # Add noise\n",
    "    noise = torch.randn_like(images) * sigma\n",
    "\n",
    "    # Forward UNet pass\n",
    "    denoised, logvar = net(images + noise, sigma, labels, return_logvar=True)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = (weight / logvar.exp()) * ((denoised - images)**2) + logvar\n",
    "    return loss\n",
    "\n",
    "\n",
    "# Inject the patch\n",
    "loop.EDM2Loss.__call__ = patched_call\n",
    "\n",
    "print(\"✅ Linear training schedule injected successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91c3f749",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T02:56:44.341988Z",
     "iopub.status.busy": "2025-11-14T02:56:44.341119Z",
     "iopub.status.idle": "2025-11-14T11:37:04.813032Z",
     "shell.execute_reply": "2025-11-14T11:37:04.812183Z"
    },
    "papermill": {
     "duration": 31220.475835,
     "end_time": "2025-11-14T11:37:04.814677",
     "exception": false,
     "start_time": "2025-11-14T02:56:44.338842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1114 02:56:46.150000 54 torch/distributed/run.py:792] \r\n",
      "W1114 02:56:46.150000 54 torch/distributed/run.py:792] *****************************************\r\n",
      "W1114 02:56:46.150000 54 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \r\n",
      "W1114 02:56:46.150000 54 torch/distributed/run.py:792] *****************************************\r\n",
      "[W1114 02:56:56.462589849 socket.cpp:204] [c10d] The hostname of the client socket cannot be retrieved. err=-3\r\n",
      "[W1114 02:57:06.473134930 socket.cpp:204] [c10d] The hostname of the client socket cannot be retrieved. err=-3\r\n",
      "[W1114 02:57:18.251279316 socket.cpp:204] [c10d] The hostname of the client socket cannot be retrieved. err=-3\r\n",
      "[W1114 02:57:18.263149146 socket.cpp:204] [c10d] The hostname of the client socket cannot be retrieved. err=-3\r\n",
      "[W1114 02:57:28.261795933 socket.cpp:204] [c10d] The hostname of the client socket cannot be retrieved. err=-3\r\n",
      "[W1114 02:57:38.269299889 socket.cpp:204] [c10d] The hostname of the client socket cannot be retrieved. err=-3\r\n",
      "Setting up training config...\r\n",
      "\r\n",
      "Training config:\r\n",
      "{\r\n",
      "  \"dataset_kwargs\": {\r\n",
      "    \"class_name\": \"training.dataset.ImageFolderDataset\",\r\n",
      "    \"path\": \"/kaggle/input/celeva-64x64-dataset/celeba64/train\",\r\n",
      "    \"use_labels\": false\r\n",
      "  },\r\n",
      "  \"encoder_kwargs\": {\r\n",
      "    \"class_name\": \"training.encoders.StandardRGBEncoder\"\r\n",
      "  },\r\n",
      "  \"total_nimg\": 2097152,\r\n",
      "  \"batch_size\": 64,\r\n",
      "  \"network_kwargs\": {\r\n",
      "    \"class_name\": \"training.networks_edm2.Precond\",\r\n",
      "    \"model_channels\": 128,\r\n",
      "    \"dropout\": 0.0,\r\n",
      "    \"use_fp16\": true\r\n",
      "  },\r\n",
      "  \"loss_kwargs\": {\r\n",
      "    \"class_name\": \"training.training_loop.EDM2Loss\",\r\n",
      "    \"P_mean\": -0.8,\r\n",
      "    \"P_std\": 1.6\r\n",
      "  },\r\n",
      "  \"lr_kwargs\": {\r\n",
      "    \"func_name\": \"training.training_loop.learning_rate_schedule\",\r\n",
      "    \"ref_lr\": 0.012,\r\n",
      "    \"ref_batches\": 35000\r\n",
      "  },\r\n",
      "  \"batch_gpu\": 32,\r\n",
      "  \"loss_scaling\": 1.0,\r\n",
      "  \"cudnn_benchmark\": true,\r\n",
      "  \"status_nimg\": 16384,\r\n",
      "  \"snapshot_nimg\": 262144,\r\n",
      "  \"checkpoint_nimg\": null,\r\n",
      "  \"seed\": 0\r\n",
      "}\r\n",
      "\r\n",
      "Output directory:        /kaggle/working/training-runs/celeba64-edm2-linear-noise-inject2\r\n",
      "Dataset path:            /kaggle/input/celeva-64x64-dataset/celeba64/train\r\n",
      "Class-conditional:       False\r\n",
      "Number of GPUs:          2\r\n",
      "Batch size:              64\r\n",
      "Mixed-precision:         True\r\n",
      "\r\n",
      "Creating output directory...\r\n",
      "[rank1]:[W1114 03:03:08.018219714 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\r\n",
      "[rank0]:[W1114 03:03:08.125438412 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\r\n",
      "Loading dataset...\r\n",
      "Setting up encoder...\r\n",
      "Constructing network...\r\n",
      "\r\n",
      "Precond                Parameters  Buffers  Output shape       Datatype\r\n",
      "---                    ---         ---      ---                ---     \r\n",
      "unet.emb_fourier       -           256      [32, 128]          float32 \r\n",
      "unet.emb_noise         65536       -        [32, 512]          float32 \r\n",
      "unet.enc.64x64_conv    4608        -        [32, 128, 64, 64]  float16 \r\n",
      "unet.enc.64x64_block0  360449      -        [32, 128, 64, 64]  float16 \r\n",
      "unet.enc.64x64_block1  360449      -        [32, 128, 64, 64]  float16 \r\n",
      "unet.enc.64x64_block2  360449      -        [32, 128, 64, 64]  float16 \r\n",
      "unet.enc.32x32_down    360449      -        [32, 128, 32, 32]  float16 \r\n",
      "unet.enc.32x32_block0  1343489     -        [32, 256, 32, 32]  float16 \r\n",
      "unet.enc.32x32_block1  1310721     -        [32, 256, 32, 32]  float16 \r\n",
      "unet.enc.32x32_block2  1310721     -        [32, 256, 32, 32]  float16 \r\n",
      "unet.enc.16x16_down    1310721     -        [32, 256, 16, 16]  float16 \r\n",
      "unet.enc.16x16_block0  3538945     -        [32, 384, 16, 16]  float16 \r\n",
      "unet.enc.16x16_block1  3440641     -        [32, 384, 16, 16]  float16 \r\n",
      "unet.enc.16x16_block2  3440641     -        [32, 384, 16, 16]  float16 \r\n",
      "unet.enc.8x8_down      2850817     -        [32, 384, 8, 8]    float16 \r\n",
      "unet.enc.8x8_block0    6225921     -        [32, 512, 8, 8]    float16 \r\n",
      "unet.enc.8x8_block1    6029313     -        [32, 512, 8, 8]    float16 \r\n",
      "unet.enc.8x8_block2    6029313     -        [32, 512, 8, 8]    float16 \r\n",
      "unet.dec.8x8_in0       6029313     -        [32, 512, 8, 8]    float16 \r\n",
      "unet.dec.8x8_in1       4980737     -        [32, 512, 8, 8]    float16 \r\n",
      "unet.dec.8x8_block0    8912897     -        [32, 512, 8, 8]    float16 \r\n",
      "unet.dec.8x8_block1    8912897     -        [32, 512, 8, 8]    float16 \r\n",
      "unet.dec.8x8_block2    8912897     -        [32, 512, 8, 8]    float16 \r\n",
      "unet.dec.8x8_block3    8257537     -        [32, 512, 8, 8]    float16 \r\n",
      "unet.dec.16x16_up      4980737     -        [32, 512, 16, 16]  float16 \r\n",
      "unet.dec.16x16_block0  5554177     -        [32, 384, 16, 16]  float16 \r\n",
      "unet.dec.16x16_block1  5062657     -        [32, 384, 16, 16]  float16 \r\n",
      "unet.dec.16x16_block2  5062657     -        [32, 384, 16, 16]  float16 \r\n",
      "unet.dec.16x16_block3  4571137     -        [32, 384, 16, 16]  float16 \r\n",
      "unet.dec.32x32_up      2850817     -        [32, 384, 32, 32]  float16 \r\n",
      "unet.dec.32x32_block0  2359297     -        [32, 256, 32, 32]  float16 \r\n",
      "unet.dec.32x32_block1  2031617     -        [32, 256, 32, 32]  float16 \r\n",
      "unet.dec.32x32_block2  2031617     -        [32, 256, 32, 32]  float16 \r\n",
      "unet.dec.32x32_block3  1703937     -        [32, 256, 32, 32]  float16 \r\n",
      "unet.dec.64x64_up      1310721     -        [32, 256, 64, 64]  float16 \r\n",
      "unet.dec.64x64_block0  704513      -        [32, 128, 64, 64]  float16 \r\n",
      "unet.dec.64x64_block1  540673      -        [32, 128, 64, 64]  float16 \r\n",
      "unet.dec.64x64_block2  540673      -        [32, 128, 64, 64]  float16 \r\n",
      "unet.dec.64x64_block3  540673      -        [32, 128, 64, 64]  float16 \r\n",
      "unet.out_conv          3456        -        [32, 3, 64, 64]    float16 \r\n",
      "unet                   1           -        [32, 3, 64, 64]    float16 \r\n",
      "<top-level>            128         256      [32, 3, 64, 64]    float32 \r\n",
      "---                    ---         ---      ---                ---     \r\n",
      "Total                  124198949   512      -                  -       \r\n",
      "\r\n",
      "Setting up training state...\r\n",
      "Training from 0 kimg to 2097 kimg:\r\n",
      "\r\n",
      "Status: kimg 0.0       time 1m 38s       sec/tick 97.54    sec/kimg 0.000   maintenance 97.54   cpumem 2.46   gpumem 1.87   reserved 2.24  \r\n",
      "Saving network-snapshot-0000000-0.050.pkl ... done\r\n",
      "Saving network-snapshot-0000000-0.100.pkl ... done\r\n",
      "Status: kimg 16.4      time 5m 24s       sec/tick 226.73   sec/kimg 13.749  maintenance 1.47    cpumem 3.13   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 32.8      time 9m 17s       sec/tick 233.19   sec/kimg 14.227  maintenance 0.09    cpumem 3.13   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 49.2      time 13m 14s      sec/tick 236.30   sec/kimg 14.417  maintenance 0.09    cpumem 3.13   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 65.5      time 17m 10s      sec/tick 236.43   sec/kimg 14.425  maintenance 0.09    cpumem 3.13   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 81.9      time 21m 08s      sec/tick 237.47   sec/kimg 14.488  maintenance 0.10    cpumem 3.13   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 98.3      time 25m 05s      sec/tick 237.81   sec/kimg 14.509  maintenance 0.09    cpumem 3.13   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 114.7     time 29m 04s      sec/tick 238.23   sec/kimg 14.535  maintenance 0.09    cpumem 3.13   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 131.1     time 33m 02s      sec/tick 238.48   sec/kimg 14.550  maintenance 0.09    cpumem 3.13   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 147.5     time 37m 01s      sec/tick 239.14   sec/kimg 14.590  maintenance 0.09    cpumem 3.13   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 163.8     time 41m 01s      sec/tick 239.24   sec/kimg 14.596  maintenance 0.10    cpumem 3.13   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 180.2     time 45m 00s      sec/tick 239.53   sec/kimg 14.614  maintenance 0.09    cpumem 3.13   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 196.6     time 49m 00s      sec/tick 239.53   sec/kimg 14.614  maintenance 0.09    cpumem 3.13   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 213.0     time 52m 59s      sec/tick 239.67   sec/kimg 14.622  maintenance 0.09    cpumem 3.13   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 229.4     time 56m 59s      sec/tick 239.87   sec/kimg 14.635  maintenance 0.09    cpumem 3.13   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 245.8     time 1h 00m 59s   sec/tick 239.78   sec/kimg 14.629  maintenance 0.09    cpumem 3.13   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 262.1     time 1h 04m 59s   sec/tick 240.18   sec/kimg 14.654  maintenance 0.10    cpumem 3.13   gpumem 7.70   reserved 8.03  \r\n",
      "Saving network-snapshot-0000262-0.050.pkl ... done\r\n",
      "Saving network-snapshot-0000262-0.100.pkl ... done\r\n",
      "Status: kimg 278.5     time 1h 09m 00s   sec/tick 241.24   sec/kimg 14.654  maintenance 1.14    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 294.9     time 1h 13m 00s   sec/tick 239.96   sec/kimg 14.640  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 311.3     time 1h 17m 00s   sec/tick 240.10   sec/kimg 14.649  maintenance 0.10    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 327.7     time 1h 21m 01s   sec/tick 240.26   sec/kimg 14.659  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 344.1     time 1h 25m 01s   sec/tick 240.39   sec/kimg 14.666  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 360.4     time 1h 29m 01s   sec/tick 240.34   sec/kimg 14.663  maintenance 0.10    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 376.8     time 1h 33m 02s   sec/tick 240.27   sec/kimg 14.659  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 393.2     time 1h 37m 02s   sec/tick 239.89   sec/kimg 14.636  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 409.6     time 1h 41m 02s   sec/tick 240.52   sec/kimg 14.674  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 426.0     time 1h 45m 03s   sec/tick 240.60   sec/kimg 14.680  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 442.4     time 1h 49m 03s   sec/tick 240.67   sec/kimg 14.683  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 458.8     time 1h 53m 04s   sec/tick 240.42   sec/kimg 14.669  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 475.1     time 1h 57m 04s   sec/tick 240.31   sec/kimg 14.662  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 491.5     time 2h 01m 05s   sec/tick 240.57   sec/kimg 14.678  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 507.9     time 2h 05m 05s   sec/tick 240.44   sec/kimg 14.670  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 524.3     time 2h 09m 06s   sec/tick 240.47   sec/kimg 14.671  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Saving network-snapshot-0000524-0.050.pkl ... done\r\n",
      "Saving network-snapshot-0000524-0.100.pkl ... done\r\n",
      "Status: kimg 540.7     time 2h 13m 07s   sec/tick 241.30   sec/kimg 14.665  maintenance 1.03    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 557.1     time 2h 17m 08s   sec/tick 240.67   sec/kimg 14.684  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 573.4     time 2h 21m 08s   sec/tick 240.20   sec/kimg 14.655  maintenance 0.10    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 589.8     time 2h 25m 08s   sec/tick 240.41   sec/kimg 14.668  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 606.2     time 2h 29m 09s   sec/tick 240.53   sec/kimg 14.675  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 622.6     time 2h 33m 09s   sec/tick 240.07   sec/kimg 14.647  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 639.0     time 2h 37m 09s   sec/tick 240.30   sec/kimg 14.661  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 655.4     time 2h 41m 09s   sec/tick 240.41   sec/kimg 14.668  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 671.7     time 2h 45m 10s   sec/tick 240.35   sec/kimg 14.664  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 688.1     time 2h 49m 10s   sec/tick 240.11   sec/kimg 14.649  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 704.5     time 2h 53m 10s   sec/tick 240.33   sec/kimg 14.663  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 720.9     time 2h 57m 11s   sec/tick 240.35   sec/kimg 14.664  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 737.3     time 3h 01m 11s   sec/tick 240.51   sec/kimg 14.674  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 753.7     time 3h 05m 11s   sec/tick 240.27   sec/kimg 14.659  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 770.0     time 3h 09m 12s   sec/tick 240.17   sec/kimg 14.653  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 786.4     time 3h 13m 12s   sec/tick 240.19   sec/kimg 14.654  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Saving network-snapshot-0000786-0.050.pkl ... done\r\n",
      "Saving network-snapshot-0000786-0.100.pkl ... done\r\n",
      "Status: kimg 802.8     time 3h 17m 13s   sec/tick 240.92   sec/kimg 14.641  maintenance 1.03    cpumem 3.13   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 819.2     time 3h 21m 12s   sec/tick 239.74   sec/kimg 14.627  maintenance 0.10    cpumem 3.13   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 835.6     time 3h 25m 12s   sec/tick 240.08   sec/kimg 14.647  maintenance 0.09    cpumem 3.13   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 852.0     time 3h 29m 13s   sec/tick 240.21   sec/kimg 14.656  maintenance 0.09    cpumem 3.13   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 868.4     time 3h 33m 13s   sec/tick 239.93   sec/kimg 14.638  maintenance 0.09    cpumem 3.13   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 884.7     time 3h 37m 12s   sec/tick 239.74   sec/kimg 14.627  maintenance 0.09    cpumem 3.13   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 901.1     time 3h 41m 12s   sec/tick 239.91   sec/kimg 14.637  maintenance 0.09    cpumem 3.13   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 917.5     time 3h 45m 12s   sec/tick 239.81   sec/kimg 14.631  maintenance 0.09    cpumem 3.13   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 933.9     time 3h 49m 12s   sec/tick 239.94   sec/kimg 14.639  maintenance 0.10    cpumem 3.13   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 950.3     time 3h 53m 12s   sec/tick 239.92   sec/kimg 14.637  maintenance 0.09    cpumem 3.13   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 966.7     time 3h 57m 12s   sec/tick 240.06   sec/kimg 14.647  maintenance 0.09    cpumem 3.13   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 983.0     time 4h 01m 12s   sec/tick 239.90   sec/kimg 14.636  maintenance 0.10    cpumem 3.13   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 999.4     time 4h 05m 12s   sec/tick 239.80   sec/kimg 14.631  maintenance 0.09    cpumem 3.13   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1015.8    time 4h 09m 11s   sec/tick 239.67   sec/kimg 14.622  maintenance 0.09    cpumem 3.13   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1032.2    time 4h 13m 11s   sec/tick 239.77   sec/kimg 14.629  maintenance 0.09    cpumem 3.13   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1048.6    time 4h 17m 11s   sec/tick 239.76   sec/kimg 14.628  maintenance 0.09    cpumem 3.13   gpumem 7.70   reserved 8.03  \r\n",
      "Saving network-snapshot-0001048-0.050.pkl ... done\r\n",
      "Saving network-snapshot-0001048-0.100.pkl ... done\r\n",
      "Status: kimg 1065.0    time 4h 21m 12s   sec/tick 240.83   sec/kimg 14.628  maintenance 1.15    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1081.3    time 4h 25m 12s   sec/tick 240.02   sec/kimg 14.644  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1097.7    time 4h 29m 12s   sec/tick 239.84   sec/kimg 14.633  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1114.1    time 4h 33m 12s   sec/tick 240.01   sec/kimg 14.643  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1130.5    time 4h 37m 11s   sec/tick 239.88   sec/kimg 14.635  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1146.9    time 4h 41m 11s   sec/tick 239.92   sec/kimg 14.638  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1163.3    time 4h 45m 12s   sec/tick 240.13   sec/kimg 14.650  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1179.6    time 4h 49m 12s   sec/tick 240.10   sec/kimg 14.649  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1196.0    time 4h 53m 12s   sec/tick 240.38   sec/kimg 14.666  maintenance 0.10    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1212.4    time 4h 57m 12s   sec/tick 240.49   sec/kimg 14.673  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1228.8    time 5h 01m 13s   sec/tick 240.76   sec/kimg 14.689  maintenance 0.10    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1245.2    time 5h 05m 14s   sec/tick 241.01   sec/kimg 14.705  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1261.6    time 5h 09m 15s   sec/tick 240.72   sec/kimg 14.687  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1278.0    time 5h 13m 15s   sec/tick 240.48   sec/kimg 14.672  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1294.3    time 5h 17m 16s   sec/tick 240.86   sec/kimg 14.695  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1310.7    time 5h 21m 17s   sec/tick 240.39   sec/kimg 14.667  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Saving network-snapshot-0001310-0.050.pkl ... done\r\n",
      "Saving network-snapshot-0001310-0.100.pkl ... done\r\n",
      "Status: kimg 1327.1    time 5h 25m 18s   sec/tick 241.73   sec/kimg 14.683  maintenance 1.17    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1343.5    time 5h 29m 19s   sec/tick 240.66   sec/kimg 14.683  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1359.9    time 5h 33m 20s   sec/tick 240.64   sec/kimg 14.682  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1376.3    time 5h 37m 20s   sec/tick 240.61   sec/kimg 14.680  maintenance 0.10    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1392.6    time 5h 41m 21s   sec/tick 240.95   sec/kimg 14.700  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1409.0    time 5h 45m 22s   sec/tick 240.70   sec/kimg 14.685  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1425.4    time 5h 49m 22s   sec/tick 240.32   sec/kimg 14.662  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1441.8    time 5h 53m 23s   sec/tick 240.72   sec/kimg 14.687  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1458.2    time 5h 57m 24s   sec/tick 240.56   sec/kimg 14.677  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1474.6    time 6h 01m 25s   sec/tick 240.94   sec/kimg 14.700  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1490.9    time 6h 05m 25s   sec/tick 240.74   sec/kimg 14.688  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1507.3    time 6h 09m 26s   sec/tick 240.49   sec/kimg 14.673  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1523.7    time 6h 13m 27s   sec/tick 241.01   sec/kimg 14.705  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1540.1    time 6h 17m 28s   sec/tick 240.90   sec/kimg 14.698  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1556.5    time 6h 21m 28s   sec/tick 240.65   sec/kimg 14.682  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1572.9    time 6h 25m 29s   sec/tick 240.60   sec/kimg 14.679  maintenance 0.10    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Saving network-snapshot-0001572-0.050.pkl ... done\r\n",
      "Saving network-snapshot-0001572-0.100.pkl ... done\r\n",
      "Status: kimg 1589.2    time 6h 29m 31s   sec/tick 241.87   sec/kimg 14.692  maintenance 1.16    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1605.6    time 6h 33m 32s   sec/tick 240.74   sec/kimg 14.688  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1622.0    time 6h 37m 32s   sec/tick 240.78   sec/kimg 14.691  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1638.4    time 6h 41m 33s   sec/tick 240.54   sec/kimg 14.676  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1654.8    time 6h 45m 34s   sec/tick 240.78   sec/kimg 14.690  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1671.2    time 6h 49m 34s   sec/tick 240.09   sec/kimg 14.648  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1687.6    time 6h 53m 34s   sec/tick 240.20   sec/kimg 14.655  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1703.9    time 6h 57m 35s   sec/tick 240.55   sec/kimg 14.676  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1720.3    time 7h 01m 35s   sec/tick 240.50   sec/kimg 14.673  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1736.7    time 7h 05m 36s   sec/tick 240.82   sec/kimg 14.693  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1753.1    time 7h 09m 37s   sec/tick 240.98   sec/kimg 14.702  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1769.5    time 7h 13m 37s   sec/tick 240.60   sec/kimg 14.679  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1785.9    time 7h 17m 38s   sec/tick 240.78   sec/kimg 14.690  maintenance 0.10    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1802.2    time 7h 21m 39s   sec/tick 240.77   sec/kimg 14.690  maintenance 0.10    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1818.6    time 7h 25m 40s   sec/tick 240.97   sec/kimg 14.702  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1835.0    time 7h 29m 41s   sec/tick 240.75   sec/kimg 14.689  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Saving network-snapshot-0001835-0.050.pkl ... done\r\n",
      "Saving network-snapshot-0001835-0.100.pkl ... done\r\n",
      "Status: kimg 1851.4    time 7h 33m 42s   sec/tick 241.73   sec/kimg 14.691  maintenance 1.03    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1867.8    time 7h 37m 43s   sec/tick 240.86   sec/kimg 14.695  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1884.2    time 7h 41m 44s   sec/tick 240.45   sec/kimg 14.670  maintenance 0.10    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1900.5    time 7h 45m 44s   sec/tick 240.62   sec/kimg 14.681  maintenance 0.10    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1916.9    time 7h 49m 45s   sec/tick 240.33   sec/kimg 14.663  maintenance 0.10    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1933.3    time 7h 53m 46s   sec/tick 240.96   sec/kimg 14.701  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1949.7    time 7h 57m 46s   sec/tick 240.55   sec/kimg 14.677  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1966.1    time 8h 01m 47s   sec/tick 240.68   sec/kimg 14.684  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1982.5    time 8h 05m 47s   sec/tick 240.55   sec/kimg 14.676  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 1998.8    time 8h 09m 48s   sec/tick 240.62   sec/kimg 14.680  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 2015.2    time 8h 13m 49s   sec/tick 240.75   sec/kimg 14.688  maintenance 0.10    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 2031.6    time 8h 17m 49s   sec/tick 240.62   sec/kimg 14.681  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 2048.0    time 8h 21m 50s   sec/tick 240.71   sec/kimg 14.686  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 2064.4    time 8h 25m 51s   sec/tick 240.60   sec/kimg 14.679  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 2080.8    time 8h 29m 51s   sec/tick 240.68   sec/kimg 14.684  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Status: kimg 2097.2    time 8h 33m 52s   sec/tick 240.17   sec/kimg 14.653  maintenance 0.09    cpumem 3.26   gpumem 7.70   reserved 8.03  \r\n",
      "Saving network-snapshot-0002097-0.050.pkl ... done\r\n",
      "Saving network-snapshot-0002097-0.100.pkl ... done\r\n",
      "[rank0]:[W1114 11:37:03.421302643 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\r\n"
     ]
    }
   ],
   "source": [
    "!torchrun --standalone --nproc_per_node=2 train_edm2.py \\\n",
    "    --outdir=/kaggle/working/training-runs/celeba64-edm2-linear-noise-inject2 \\\n",
    "    --data=/kaggle/input/celeva-64x64-dataset/celeba64/train \\\n",
    "    --cond=False \\\n",
    "    --preset=edm2-img64-xs \\\n",
    "    --batch=64 \\\n",
    "    --batch-gpu=32 \\\n",
    "    --duration=2Mi \\\n",
    "    --status=16Ki \\\n",
    "    --snapshot=256Ki \\\n",
    "    --checkpoint=0 \\\n",
    "    --seed=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bb8a950",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T11:37:04.833236Z",
     "iopub.status.busy": "2025-11-14T11:37:04.832975Z",
     "iopub.status.idle": "2025-11-14T11:37:04.963924Z",
     "shell.execute_reply": "2025-11-14T11:37:04.963237Z"
    },
    "papermill": {
     "duration": 0.141737,
     "end_time": "2025-11-14T11:37:04.965094",
     "exception": false,
     "start_time": "2025-11-14T11:37:04.823357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tail: cannot open '/kaggle/working/training-runs/celeba64-edm2-linear/log.txt' for reading: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!tail -n 20 /kaggle/working/training-runs/celeba64-edm2-linear/log.txt"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8713085,
     "sourceId": 13697783,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 31239.435668,
   "end_time": "2025-11-14T11:37:05.692108",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-14T02:56:26.256440",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
