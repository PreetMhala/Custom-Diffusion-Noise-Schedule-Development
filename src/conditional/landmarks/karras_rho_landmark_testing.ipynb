{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3146270f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-09T17:32:15.786718Z",
     "iopub.status.busy": "2025-12-09T17:32:15.786429Z",
     "iopub.status.idle": "2025-12-09T17:32:24.080616Z",
     "shell.execute_reply": "2025-12-09T17:32:24.079713Z"
    },
    "papermill": {
     "duration": 8.299937,
     "end_time": "2025-12-09T17:32:24.082036",
     "exception": false,
     "start_time": "2025-12-09T17:32:15.782099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'edm2'...\r\n",
      "remote: Enumerating objects: 60, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (27/27), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (17/17), done.\u001b[K\r\n",
      "remote: Total 60 (delta 13), reused 10 (delta 10), pack-reused 33 (from 1)\u001b[K\r\n",
      "Receiving objects: 100% (60/60), 1.27 MiB | 9.80 MiB/s, done.\r\n",
      "Resolving deltas: 100% (24/24), done.\r\n",
      "/kaggle/working/edm2\n",
      "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\r\n",
      "\u001b[0m/kaggle/working\n",
      "EDM2 setup complete!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# üì¶ BLOCK 1 ‚Äî Install Dependencies & Clone EDM2 Repository\n",
    "# ============================================================\n",
    "\n",
    "!pip install click tqdm psutil scipy pillow pandas --quiet\n",
    "\n",
    "# Clone EDM2 repo\n",
    "!git clone https://github.com/NVlabs/edm2.git\n",
    "%cd edm2\n",
    "\n",
    "# Try to install remaining deps (ignore if file missing)\n",
    "!pip install -r requirements.txt --quiet || true\n",
    "\n",
    "# Return to working directory\n",
    "%cd /kaggle/working\n",
    "\n",
    "print(\"EDM2 setup complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "441018cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T17:32:24.089338Z",
     "iopub.status.busy": "2025-12-09T17:32:24.089111Z",
     "iopub.status.idle": "2025-12-09T17:35:36.398502Z",
     "shell.execute_reply": "2025-12-09T17:35:36.397785Z"
    },
    "papermill": {
     "duration": 192.317175,
     "end_time": "2025-12-09T17:35:36.402449",
     "exception": false,
     "start_time": "2025-12-09T17:32:24.085274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test images: 19962\n",
      "Valid test images (in CSV): 19962\n",
      "Saved:\n",
      "/kaggle/working/landmark-cond-test-labels/landmark_labels_full.npy\n",
      "/kaggle/working/landmark-cond-test-labels/filenames_full.npy\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# üß© BLOCK 2 ‚Äî Prepare FULL Test Landmark Labels + Filenames\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "LANDMARK_CSV = \"/kaggle/input/bbox-and-landmark-conditioning-csv-aligned-files/celeba64_landmarks_transformed.csv\"\n",
    "TEST_DIR     = \"/kaggle/input/celeva-64x64-dataset/celeba64/test\"\n",
    "OUT_DIR      = \"/kaggle/working/landmark-cond-test-labels\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# Load landmark CSV\n",
    "df = pd.read_csv(LANDMARK_CSV)\n",
    "\n",
    "img_col = df.columns[0]       # \"image_id\"\n",
    "landmark_cols = df.columns[1:]  # 10 columns (x1,y1,...,x5,y5)\n",
    "\n",
    "landmarks = df[landmark_cols].values.astype(np.float32)\n",
    "\n",
    "# Get test images\n",
    "test_files = sorted([f for f in os.listdir(TEST_DIR) if f.endswith(\".jpg\")])\n",
    "print(\"Total test images:\", len(test_files))\n",
    "\n",
    "# Keep only those that exist in CSV\n",
    "valid_test_files = [f for f in test_files if f in df[img_col].values]\n",
    "print(\"Valid test images (in CSV):\", len(valid_test_files))\n",
    "\n",
    "# Build full label array in same test order\n",
    "labels_full = np.array([\n",
    "    landmarks[df[img_col].values.tolist().index(f)]\n",
    "    for f in valid_test_files\n",
    "], dtype=np.float32)\n",
    "\n",
    "filenames_full = np.array(valid_test_files)\n",
    "\n",
    "# Save arrays\n",
    "np.save(f\"{OUT_DIR}/landmark_labels_full.npy\", labels_full)\n",
    "np.save(f\"{OUT_DIR}/filenames_full.npy\", filenames_full)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(f\"{OUT_DIR}/landmark_labels_full.npy\")\n",
    "print(f\"{OUT_DIR}/filenames_full.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a214474",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T17:35:36.409181Z",
     "iopub.status.busy": "2025-12-09T17:35:36.408711Z",
     "iopub.status.idle": "2025-12-09T17:35:36.414985Z",
     "shell.execute_reply": "2025-12-09T17:35:36.414247Z"
    },
    "papermill": {
     "duration": 0.010844,
     "end_time": "2025-12-09T17:35:36.416085",
     "exception": false,
     "start_time": "2025-12-09T17:35:36.405241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ gen_landmark_conditional.py written successfully!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# üé® BLOCK 3 ‚Äî Write Landmark Conditional Generator Script\n",
    "# ============================================================\n",
    "\n",
    "generator_code = r'''\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import sys\n",
    "\n",
    "# Ensure EDM2 repo is importable\n",
    "sys.path.append(\"/kaggle/working/edm2\")\n",
    "from edm2.generate_images import edm_sampler\n",
    "\n",
    "def generate_landmark_conditional(model, labels, names, outdir,\n",
    "                                  steps=32, sigma_min=0.002, sigma_max=80, rho=7):\n",
    "\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print(\"Loading model:\", model)\n",
    "    with open(model, \"rb\") as f:\n",
    "        net = pickle.load(f)[\"ema\"].to(device).eval()\n",
    "\n",
    "    # Load 10-dim labels and names\n",
    "    labels_np = np.load(labels)         # shape (N,10)\n",
    "    filenames = np.load(names)          # shape (N,)\n",
    "\n",
    "    N = labels_np.shape[0]\n",
    "    print(f\"Generating {N} images...\")\n",
    "\n",
    "    bs_max = 64\n",
    "\n",
    "    for start in range(0, N, bs_max):\n",
    "        bs = min(bs_max, N - start)\n",
    "\n",
    "        cond = torch.tensor(labels_np[start:start+bs], dtype=torch.float32, device=device)\n",
    "\n",
    "        # noise input (same shape as EDM2 expects)\n",
    "        noise = torch.randn(bs,\n",
    "                            net.img_channels,\n",
    "                            net.img_resolution,\n",
    "                            net.img_resolution,\n",
    "                            device=device)\n",
    "\n",
    "        imgs = edm_sampler(\n",
    "            net=net,\n",
    "            noise=noise,\n",
    "            labels=cond,\n",
    "            num_steps=steps,\n",
    "            sigma_min=sigma_min,\n",
    "            sigma_max=sigma_max,\n",
    "            rho=rho,\n",
    "        )\n",
    "\n",
    "        imgs = imgs.clamp(-1, 1)\n",
    "        imgs = (imgs * 127.5 + 127.5).to(torch.uint8)\n",
    "        imgs = imgs.permute(0, 2, 3, 1).cpu().numpy()\n",
    "\n",
    "        for j in range(bs):\n",
    "            outname = filenames[start + j].replace(\".jpg\", \".png\")\n",
    "            PIL.Image.fromarray(imgs[j]).save(os.path.join(outdir, outname))\n",
    "\n",
    "    print(\"DONE! Saved images to\", outdir)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument(\"--model\", type=str, required=True)\n",
    "    parser.add_argument(\"--labels\", type=str, required=True)\n",
    "    parser.add_argument(\"--names\", type=str, required=True)\n",
    "    parser.add_argument(\"--outdir\", type=str, required=True)\n",
    "    parser.add_argument(\"--steps\", type=int, default=32)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    generate_landmark_conditional(\n",
    "        model=args.model,\n",
    "        labels=args.labels,\n",
    "        names=args.names,\n",
    "        outdir=args.outdir,\n",
    "        steps=args.steps,\n",
    "    )\n",
    "'''\n",
    "\n",
    "with open(\"gen_landmark_conditional.py\", \"w\") as f:\n",
    "    f.write(generator_code)\n",
    "\n",
    "print(\"‚úÖ gen_landmark_conditional.py written successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efdcb3a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T17:35:36.422920Z",
     "iopub.status.busy": "2025-12-09T17:35:36.422360Z",
     "iopub.status.idle": "2025-12-09T20:17:02.300050Z",
     "shell.execute_reply": "2025-12-09T20:17:02.299224Z"
    },
    "papermill": {
     "duration": 9685.882762,
     "end_time": "2025-12-09T20:17:02.301584",
     "exception": false,
     "start_time": "2025-12-09T17:35:36.418822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: /kaggle/input/network-snapshot-0001572-0-100-landmark-karrasrho/pytorch/default/1/network-snapshot-0001572-0.100_landmark_karrasrho.pkl\r\n",
      "Generating 19962 images...\r\n",
      "DONE! Saved images to /kaggle/working/landmark-cond-generated-full\r\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# üöÄ BLOCK 4 ‚Äî Run Conditional Generation (FULL landmark test set)\n",
    "# ============================================================\n",
    "\n",
    "MODEL_PKL = \"/kaggle/input/network-snapshot-0001572-0-100-landmark-karrasrho/pytorch/default/1/network-snapshot-0001572-0.100_landmark_karrasrho.pkl\"\n",
    "\n",
    "LABELS_FULL    = \"/kaggle/working/landmark-cond-test-labels/landmark_labels_full.npy\"\n",
    "FILENAMES_FULL = \"/kaggle/working/landmark-cond-test-labels/filenames_full.npy\"\n",
    "\n",
    "OUT_IMAGES = \"/kaggle/working/landmark-cond-generated-full\"\n",
    "\n",
    "!python gen_landmark_conditional.py \\\n",
    "    --model \"$MODEL_PKL\" \\\n",
    "    --labels \"$LABELS_FULL\" \\\n",
    "    --names \"$FILENAMES_FULL\" \\\n",
    "    --outdir \"$OUT_IMAGES\" \\\n",
    "    --steps 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90f95318",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T20:17:02.309432Z",
     "iopub.status.busy": "2025-12-09T20:17:02.309170Z",
     "iopub.status.idle": "2025-12-09T20:19:03.181696Z",
     "shell.execute_reply": "2025-12-09T20:19:03.180932Z"
    },
    "papermill": {
     "duration": 120.878369,
     "end_time": "2025-12-09T20:19:03.183374",
     "exception": false,
     "start_time": "2025-12-09T20:17:02.305005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from /kaggle/input/celeva-64x64-dataset/celeba64/test ...\r\n",
      "[rank0]:[W1209 20:17:39.701460481 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\r\n",
      "Setting up InceptionV3Detector...\r\n",
      "Calculating feature statistics...\r\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 312/312 [01:19<00:00,  3.90batch/s]\r\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# üìä BLOCK 5 ‚Äî Compute CelebA64 Reference Stats\n",
    "# ============================================================\n",
    "\n",
    "!python /kaggle/working/edm2/calculate_metrics.py ref \\\n",
    "    --data=\"/kaggle/input/celeva-64x64-dataset/celeba64/test\" \\\n",
    "    --dest=\"/kaggle/working/celeba64_ref.pkl\" \\\n",
    "    --metrics=fid \\\n",
    "    --batch=64 \\\n",
    "    --workers=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df8fc450",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T20:19:03.216724Z",
     "iopub.status.busy": "2025-12-09T20:19:03.215959Z",
     "iopub.status.idle": "2025-12-09T20:19:03.220338Z",
     "shell.execute_reply": "2025-12-09T20:19:03.219826Z"
    },
    "papermill": {
     "duration": 0.022118,
     "end_time": "2025-12-09T20:19:03.221455",
     "exception": false,
     "start_time": "2025-12-09T20:19:03.199337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ============================================================\n",
    "# # üß© BLOCK A ‚Äî Create Smaller Test Set (20 Samples)\n",
    "# # ============================================================\n",
    "\n",
    "# import numpy as np\n",
    "# import os\n",
    "\n",
    "# LABELS_FULL = \"/kaggle/working/landmark-cond-test-labels/landmark_labels_full.npy\"\n",
    "# FILENAMES_FULL = \"/kaggle/working/landmark-cond-test-labels/filenames_full.npy\"\n",
    "\n",
    "# # Load full arrays\n",
    "# labels_full = np.load(LABELS_FULL)\n",
    "# filenames_full = np.load(FILENAMES_FULL)\n",
    "\n",
    "# # Select first 20 images for quick test\n",
    "# N_TEST = 20\n",
    "# labels_20 = labels_full[:N_TEST]\n",
    "# names_20  = filenames_full[:N_TEST]\n",
    "\n",
    "# # Save small versions\n",
    "# np.save(\"/kaggle/working/landmark-cond-test-labels/labels_20.npy\", labels_20)\n",
    "# np.save(\"/kaggle/working/landmark-cond-test-labels/names_20.npy\", names_20)\n",
    "\n",
    "# print(\"Created small test set:\")\n",
    "# print(\"labels_20.npy shape ->\", labels_20.shape)\n",
    "# print(\"names_20.npy count  ->\", len(names_20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e1d99bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T20:19:03.251752Z",
     "iopub.status.busy": "2025-12-09T20:19:03.251541Z",
     "iopub.status.idle": "2025-12-09T20:19:03.254709Z",
     "shell.execute_reply": "2025-12-09T20:19:03.254172Z"
    },
    "papermill": {
     "duration": 0.019285,
     "end_time": "2025-12-09T20:19:03.255736",
     "exception": false,
     "start_time": "2025-12-09T20:19:03.236451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ============================================================\n",
    "# # üöÄ BLOCK B ‚Äî Generate Images for 20 Test Samples\n",
    "# # ============================================================\n",
    "\n",
    "# MODEL_PKL = \"/kaggle/input/network-snapshot-0001572-0-100-landmark-karrasrho/pytorch/default/1/network-snapshot-0001572-0.100_landmark_karrasrho.pkl\"\n",
    "\n",
    "# LABELS_20    = \"/kaggle/working/landmark-cond-test-labels/labels_20.npy\"\n",
    "# NAMES_20     = \"/kaggle/working/landmark-cond-test-labels/names_20.npy\"\n",
    "# OUT_IMAGES_20 = \"/kaggle/working/landmark-cond-generated-20\"\n",
    "\n",
    "# !python gen_landmark_conditional.py \\\n",
    "#     --model \"$MODEL_PKL\" \\\n",
    "#     --labels \"$LABELS_20\" \\\n",
    "#     --names \"$NAMES_20\" \\\n",
    "#     --outdir \"$OUT_IMAGES_20\" \\\n",
    "#     --steps 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "251b306e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T20:19:03.288141Z",
     "iopub.status.busy": "2025-12-09T20:19:03.287648Z",
     "iopub.status.idle": "2025-12-09T20:19:03.291143Z",
     "shell.execute_reply": "2025-12-09T20:19:03.290529Z"
    },
    "papermill": {
     "duration": 0.020403,
     "end_time": "2025-12-09T20:19:03.292331",
     "exception": false,
     "start_time": "2025-12-09T20:19:03.271928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # OPTIONAL: Display few generated samples\n",
    "# import os\n",
    "# from PIL import Image\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# folder = \"/kaggle/working/landmark-cond-generated-20\"\n",
    "# files = sorted(os.listdir(folder))[:5]\n",
    "\n",
    "# plt.figure(figsize=(12,5))\n",
    "# for i,f in enumerate(files):\n",
    "#     img = Image.open(os.path.join(folder, f))\n",
    "#     plt.subplot(1,5,i+1)\n",
    "#     plt.imshow(img)\n",
    "#     plt.axis(\"off\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b97a4fb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T20:19:03.325618Z",
     "iopub.status.busy": "2025-12-09T20:19:03.324746Z",
     "iopub.status.idle": "2025-12-09T20:19:03.328685Z",
     "shell.execute_reply": "2025-12-09T20:19:03.327969Z"
    },
    "papermill": {
     "duration": 0.021898,
     "end_time": "2025-12-09T20:19:03.329999",
     "exception": false,
     "start_time": "2025-12-09T20:19:03.308101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ============================================================\n",
    "# # üîÅ ONE-TIME ‚Äî Compute CelebA64 Reference Stats (Test Set)\n",
    "# # ============================================================\n",
    "\n",
    "# !python /kaggle/working/edm2/calculate_metrics.py ref \\\n",
    "#     --data=\"/kaggle/input/celeva-64x64-dataset/celeba64/test\" \\\n",
    "#     --dest=\"/kaggle/working/celeba64_ref.pkl\" \\\n",
    "#     --metrics=fid \\\n",
    "#     --batch=64 \\\n",
    "#     --workers=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d911913",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T20:19:03.361776Z",
     "iopub.status.busy": "2025-12-09T20:19:03.361336Z",
     "iopub.status.idle": "2025-12-09T20:19:03.364822Z",
     "shell.execute_reply": "2025-12-09T20:19:03.364140Z"
    },
    "papermill": {
     "duration": 0.020476,
     "end_time": "2025-12-09T20:19:03.365956",
     "exception": false,
     "start_time": "2025-12-09T20:19:03.345480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ============================================================\n",
    "# # OPTIONAL ‚Äî Compute FID for 20 sample images\n",
    "# # ============================================================\n",
    "\n",
    "# !torchrun --standalone --nproc_per_node=1 \\\n",
    "#     /kaggle/working/edm2/calculate_metrics.py calc \\\n",
    "#     --images=\"/kaggle/working/landmark-cond-generated-20\" \\\n",
    "#     --ref=\"/kaggle/working/celeba64_ref.pkl\" \\\n",
    "#     --metrics=fid \\\n",
    "#     --num=20 \\\n",
    "#     --batch=20 \\\n",
    "#     --workers=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a286db67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T20:19:03.396682Z",
     "iopub.status.busy": "2025-12-09T20:19:03.396466Z",
     "iopub.status.idle": "2025-12-09T20:19:59.860761Z",
     "shell.execute_reply": "2025-12-09T20:19:59.859695Z"
    },
    "papermill": {
     "duration": 56.481655,
     "end_time": "2025-12-09T20:19:59.862447",
     "exception": false,
     "start_time": "2025-12-09T20:19:03.380792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1209 20:19:05.329000 101 torch/distributed/run.py:792] \r\n",
      "W1209 20:19:05.329000 101 torch/distributed/run.py:792] *****************************************\r\n",
      "W1209 20:19:05.329000 101 torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \r\n",
      "W1209 20:19:05.329000 101 torch/distributed/run.py:792] *****************************************\r\n",
      "[W1209 20:19:05.852224813 socket.cpp:204] [c10d] The hostname of the client socket cannot be retrieved. err=-3\r\n",
      "[W1209 20:19:05.852923825 socket.cpp:204] [c10d] The hostname of the client socket cannot be retrieved. err=-3\r\n",
      "[W1209 20:19:07.836761898 socket.cpp:204] [c10d] The hostname of the client socket cannot be retrieved. err=-3\r\n",
      "[W1209 20:19:07.837623606 socket.cpp:204] [c10d] The hostname of the client socket cannot be retrieved. err=-3\r\n",
      "[W1209 20:19:07.839617743 socket.cpp:204] [c10d] The hostname of the client socket cannot be retrieved. err=-3\r\n",
      "[W1209 20:19:07.840318362 socket.cpp:204] [c10d] The hostname of the client socket cannot be retrieved. err=-3\r\n",
      "Loading feature statistics from /kaggle/working/celeba64_ref.pkl ...\r\n",
      "Loading images from /kaggle/working/landmark-cond-generated-full ...\r\n",
      "[rank1]:[W1209 20:19:07.035676063 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\r\n",
      "[rank0]:[W1209 20:19:07.222891922 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\r\n",
      "Setting up InceptionV3Detector...\r\n",
      "Calculating feature statistics...\r\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 156/156 [00:43<00:00,  3.60batch/s]\r\n",
      "Calculating fid...\r\n",
      "fid = 28.3906\r\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# üßÆ BLOCK 6 ‚Äî Compute FID for Landmark Model Output\n",
    "# ============================================================\n",
    "\n",
    "NUM_FULL = len(os.listdir(\"/kaggle/working/landmark-cond-generated-full\"))\n",
    "\n",
    "!torchrun --standalone --nproc_per_node=2 \\\n",
    "    /kaggle/working/edm2/calculate_metrics.py calc \\\n",
    "    --images=\"/kaggle/working/landmark-cond-generated-full\" \\\n",
    "    --ref=\"/kaggle/working/celeba64_ref.pkl\" \\\n",
    "    --metrics=fid \\\n",
    "    --num=$NUM_FULL \\\n",
    "    --batch=64 \\\n",
    "    --workers=2\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8713093,
     "sourceId": 13697793,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8944182,
     "sourceId": 14051337,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 528898,
     "modelInstanceId": 514256,
     "sourceId": 678090,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10070.079375,
   "end_time": "2025-12-09T20:20:00.404912",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-09T17:32:10.325537",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
